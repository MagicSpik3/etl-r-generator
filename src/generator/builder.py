from typing import List, Dict, Callable
from src.ir.model import Pipeline, Operation
from src.ir.types import OpType
from src.generator.transpiler import RTranspiler


class RGenerator:
    """
    The Master Builder.
    Converts a Logical Pipeline into an R Script using a Visitor Pattern.
    """
    
    def __init__(self, pipeline: Pipeline):
        self.pipeline = pipeline
        self.lines: List[str] = []
        self.transpiler = RTranspiler()
        
        # 游릭 THE DISPATCH TABLE
        # Maps OpType to the method that handles it.
        # This removes the need for giant if/elif chains.
        self._dispatch_map = {
            OpType.LOAD_CSV: self._gen_load_csv,
            OpType.SAVE_BINARY: self._gen_save_binary,
            OpType.FILTER: self._gen_filter,
            OpType.SORT: self._gen_sort,
            OpType.JOIN: self._gen_join,
            OpType.BATCH_COMPUTE: self._gen_batch_compute,
            OpType.MATERIALIZE: self._gen_pass_through,  # <--- NEW!
            OpType.COMPUTE: self._gen_compute_columns, # <--- NEW
            OpType.GENERIC: self._gen_generic # <--- Placeholder
        }

    def generate(self) -> str:
        self.lines = []
        self._add_header()
        self._add_imports()
        self._add_body()
        return "\n".join(self.lines)

    def _add_header(self):
        gen_name = self.pipeline.metadata.get("generator", "Unknown")
        self.lines.append(f"# Auto-Generated ETL Script")
        self.lines.append(f"# Generated by: {gen_name}")
        self.lines.append(f"# Dialect: Tidyverse")
        self.lines.append("")

    def _add_imports(self):
        self.lines.append("library(tidyverse)")
        self.lines.append("library(lubridate)")
        self.lines.append("")

    def _add_body(self):
        """
        Iterates through operations and dispatches to the correct handler.
        """
        for op in self.pipeline.operations:
            self.lines.append(f"# Op: {op.id}")
            
            # 游릭 The "Visitor" Logic
            # Look up the handler in the table
            handler = self._dispatch_map.get(op.type)
            
            if handler:
                # Execute the handler
                handler(op)
            else:
                # Graceful fallback for unimplemented ops
                self.lines.append(f"# WARNING: No generator implemented for {op.type}")
                
            self.lines.append("")

    # --- Handlers ---

    def _gen_load_csv(self, op: Operation):
        target = op.outputs[0]
        # 游릭 FIX: Use the actual filename param from SPSS, fallback to ID if missing
        filename = op.parameters.get("filename", op.outputs[0])
        
        # Clean up path issues (optional, but safe)
        # If SPSS had FILE='/data/demo.csv', we might want just 'demo.csv' 
        # for this flat-folder demo.
        import os
        filename = os.path.basename(filename)
        
        self.lines.append(f'{target} <- read_csv("{filename}")')


    def _gen_save_binary(self, op: Operation):
        source = op.inputs[0]
        filename = op.outputs[0]
        self.lines.append(f'write_csv({source}, "{filename}")')

    def _gen_filter(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        raw_condition = op.parameters.get("condition", "TRUE")
        condition = self.transpiler.transpile(raw_condition)
        self.lines.append(f"{target} <- {source} %>% filter({condition})")

    def _gen_sort(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        keys = op.parameters.get("keys", "")
        self.lines.append(f"{target} <- {source} %>% arrange({keys})")

    def _gen_join(self, op: Operation):
        target = op.outputs[0]
        left = op.inputs[0]
        right = op.inputs[1] if len(op.inputs) > 1 else "ERROR_MISSING_INPUT"
        self.lines.append(f"{target} <- {left} %>% inner_join({right})")


    
    def _gen_batch_compute(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        computes = op.parameters.get("computes", [])
        
        if not computes:
            # If empty batch, just assign
            self.lines.append(f"{target} <- {source}")
            return

        self.lines.append(f"{target} <- {source} %>%")
        self.lines.append("  mutate(")
        
        # Iterate through the batch list
        for i, comp in enumerate(computes):
            var_name = comp.get("target")
            raw_expr = comp.get("expression")
            
            # 游릭 Transpile the expression logic!
            expr = self.transpiler.transpile(raw_expr)
            
            # Add comma if not the last item
            separator = "," if i < len(computes) - 1 else ""
            self.lines.append(f"    {var_name} = {expr}{separator}")
            
        self.lines.append("  )")        


    def _gen_pass_through(self, op: Operation):
        """
        Handles MATERIALIZE or EXECUTE nodes.
        In R, this is just a variable assignment to keep the lineage intact.
        ds_next <- ds_prev
        """
        target = op.outputs[0]
        source = op.inputs[0]
        self.lines.append(f"{target} <- {source}")

    def _gen_compute_columns(self, op: Operation):
        """
        Handles a standalone COMPUTE that wasn't merged into a batch.
        """
        target = op.outputs[0]
        source = op.inputs[0]
        
        # Get params
        var_name = op.parameters.get("target")
        raw_expr = op.parameters.get("expression")
        expr = self.transpiler.transpile(raw_expr)
        
        self.lines.append(f"{target} <- {source} %>% mutate({var_name} = {expr})")

    def _gen_generic(self, op: Operation):
        """
        Fallback for things SpecGen couldn't fully parse (like complex IFs).
        We just comment it out so the script doesn't crash.
        """
        cmd = op.parameters.get("command", "UNKNOWN")
        self.lines.append(f"# WARNING: Generic command '{cmd}' not fully supported yet.")
        self.lines.append(f"# {op.outputs[0]} <- {op.inputs[0]}")