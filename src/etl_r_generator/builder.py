from typing import List, Dict, Callable
from etl_ir.model import Pipeline, Operation
from etl_ir.types import DataType, OpType
from etl_r_generator.transpiler import RTranspiler
import os

class RGenerator:
    """
    The Master Builder.
    Converts a Logical Pipeline into an R Script using a Visitor Pattern.
    """
    
    def __init__(self, pipeline: Pipeline):
        self.pipeline = pipeline
        self.lines: List[str] = []
        self.transpiler = RTranspiler()
        
        # 游릭 THE DISPATCH TABLE
        self._dispatch_map = {
            OpType.LOAD_CSV: self._gen_load_csv,
            OpType.SAVE_BINARY: self._gen_save_binary,
            OpType.FILTER_ROWS: self._gen_filter,
            OpType.SORT_ROWS: self._gen_sort,
            OpType.JOIN: self._gen_join,
            OpType.BATCH_COMPUTE: self._gen_batch_compute,
            OpType.MATERIALIZE: self._gen_pass_through,
            OpType.COMPUTE_COLUMNS: self._gen_compute_columns,
            OpType.GENERIC_TRANSFORM: self._gen_generic,
            # 游릭 FIX: Point to the new dedicated handler!
            OpType.AGGREGATE: self._gen_aggregate 
        }

    def generate(self) -> str:
        self.lines = []
        self._add_header()
        self._add_imports()
        self._add_body()
        return "\n".join(self.lines)

    def _add_header(self):
        gen_name = self.pipeline.metadata.get("generator", "Unknown")
        self.lines.append(f"# Auto-Generated ETL Script")
        self.lines.append(f"# Generated by: {gen_name}")
        self.lines.append(f"# Dialect: Tidyverse")
        self.lines.append("")

    def _add_imports(self):
        self.lines.append("library(tidyverse)")
        self.lines.append("library(lubridate)")
        self.lines.append("")

    def _add_body(self):
        for op in self.pipeline.operations:
            self.lines.append(f"# Op: {op.id}")
            handler = self._dispatch_map.get(op.type)
            if handler:
                handler(op)
            else:
                self.lines.append(f"# WARNING: No generator implemented for {op.type}")
            self.lines.append("")

    # --- Handlers ---

    def _gen_load_csv(self, op: Operation):
        target = op.outputs[0]
        filename = op.parameters.get("filename", op.outputs[0])
        filename = os.path.basename(filename)
        self.lines.append(f'{target} <- read_csv("{filename}")')


    def _gen_save_binary(self, op: Operation):
        source = op.inputs[0]
        # 游릭 FIX: Check parameters for the real filename first!
        # Fallback to outputs[0] only if parameter is missing.
        filename = op.parameters.get("filename", op.outputs[0])
        self.lines.append(f'write_csv({source}, "{filename}")')

    def _gen_filter(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        raw_condition = op.parameters.get("condition", "TRUE")
        condition = self.transpiler.transpile(raw_condition)
        self.lines.append(f"{target} <- {source} %>% filter({condition})")

    def _gen_sort(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        keys = op.parameters.get("keys", "")
        self.lines.append(f"{target} <- {source} %>% arrange({keys})")

    def _gen_join(self, op: Operation):
        target = op.outputs[0]
        left = op.inputs[0]
        right = op.inputs[1] if len(op.inputs) > 1 else "ERROR_MISSING_INPUT"
        self.lines.append(f"{target} <- {left} %>% inner_join({right})")
    
    def _gen_batch_compute(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        computes = op.parameters.get("computes", [])
        
        if not computes:
            self.lines.append(f"{target} <- {source}")
            return

        self.lines.append(f"{target} <- {source} %>%")
        self.lines.append("  mutate(")
        for i, comp in enumerate(computes):
            var_name = comp.get("target")
            raw_expr = comp.get("expression")
            expr = self.transpiler.transpile(raw_expr)
            separator = "," if i < len(computes) - 1 else ""
            self.lines.append(f"    {var_name} = {expr}{separator}")
        self.lines.append("  )")        

    def _gen_pass_through(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        self.lines.append(f"{target} <- {source}")

    def _gen_compute_columns(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        var_name = op.parameters.get("target")
        raw_expr = op.parameters.get("expression")
        expr = self.transpiler.transpile(raw_expr)
        self.lines.append(f"{target} <- {source} %>% mutate({var_name} = {expr})")

    def _gen_generic(self, op: Operation):
        cmd = op.parameters.get("command", "UNKNOWN")
        self.lines.append(f"# WARNING: Generic command '{cmd}' not fully supported yet.")
        self.lines.append(f"# {op.outputs[0]} <- {op.inputs[0]}")

    # 游릭 NEW HANDLER
    def _gen_aggregate(self, op: Operation):
        target = op.outputs[0]
        source = op.inputs[0]
        
        # 1. Get parameters
        break_vars = op.parameters.get('break', [])
        aggs = op.parameters.get('aggregations', [])
        
        # 2. Build group_by string
        group_str = ", ".join(break_vars)
        
        # 3. Build summarise string
        r_aggs = []
        for agg in aggs:
            if "=" in agg:
                col_name, expr = agg.split("=", 1)
                clean_expr = expr.strip()
                # Basic Mapping
                clean_expr = clean_expr.replace("MEAN(", "mean(")
                clean_expr = clean_expr.replace("SUM(", "sum(")
                clean_expr = clean_expr.replace("MAX(", "max(")
                clean_expr = clean_expr.replace("MIN(", "min(")
                
                # Safety check for NA handling
                if "(" in clean_expr and ", na.rm" not in clean_expr:
                    clean_expr = clean_expr.replace(")", ", na.rm = TRUE)")
                
                r_aggs.append(f"{col_name.strip()} = {clean_expr}")
        
        summarize_str = ", ".join(r_aggs)
        
        # 4. Generate Code
        self.lines.append(f"{target} <- {source} %>%")
        if group_str:
            self.lines.append(f"  group_by({group_str}) %>%")
        
        if not r_aggs:
             self.lines.append(f"  distinct({group_str})")
        else:
             self.lines.append(f"  summarise({summarize_str})")